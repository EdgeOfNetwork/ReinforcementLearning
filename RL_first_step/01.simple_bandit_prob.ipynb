{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18f30843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bfc157",
   "metadata": {},
   "source": [
    "## Bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881b7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#밴딧의 손잡이 목록 작성\n",
    "#현재 손잡이 4가 가장 + 보상이 좋도록 설정되어 있음 \n",
    "bandits = [0.2, 0, -0.2, -2]\n",
    "num_bandits = len(bandits)\n",
    "\n",
    "def pull_bandit(bandit):\n",
    "    result = np.random.randn(1) #랜덤한 표준 정규분포값 생성\n",
    "    if result > bandit:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44107d62",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "942476e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#네트워크의 피드포워드 부분 구현\n",
    "weights = tf.Variable(tf.ones([num_bandits]))\n",
    "chosen_action = tf.argmax(weights,0)\n",
    "\n",
    "\n",
    "reward_holder = tf.placeholder(shape=[1],dtype=tf.float32)\n",
    "action_holder = tf.placeholder(shape=[1],dtype=tf.int32)\n",
    "\n",
    "#학습 과정을 구현\n",
    "#보상과 선택된 액션을 네트워크에 피드백함으로, 비용을 계산하고 비용을 이용해 네트워크를 업데이트\n",
    "responsible_weight = tf.slice(weights,action_holder,[1])\n",
    "loss = -(tf.log(responsible_weight)*reward_holder)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "update = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27b515",
   "metadata": {},
   "source": [
    "# Training Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10157d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward for the 4 bandits:[-1.  0.  0.  0.]\n",
      "Running reward for the 4 bandits:[-3. -5. -1. 30.]\n",
      "Running reward for the 4 bandits:[-3. -5. -2. 77.]\n",
      "Running reward for the 4 bandits:[ -1.  -5.  -2. 117.]\n",
      "Running reward for the 4 bandits:[ -1.  -4.  -2. 164.]\n",
      "Running reward for the 4 bandits:[  1.  -7.  -1. 208.]\n",
      "Running reward for the 4 bandits:[  1.  -9.   0. 255.]\n",
      "Running reward for the 4 bandits:[  0. -10.   0. 301.]\n",
      "Running reward for the 4 bandits:[  0. -10.   0. 345.]\n",
      "Running reward for the 4 bandits:[  0.  -8.   1. 390.]\n",
      "Running reward for the 4 bandits:[  0.  -8.   1. 436.]\n",
      "Running reward for the 4 bandits:[ -1.  -6.   1. 477.]\n",
      "Running reward for the 4 bandits:[ -2.  -6.   1. 518.]\n",
      "Running reward for the 4 bandits:[ -1.  -7.   2. 565.]\n",
      "Running reward for the 4 bandits:[  0.  -7.   2. 610.]\n",
      "Running reward for the 4 bandits:[ -1.  -7.   2. 655.]\n",
      "Running reward for the 4 bandits:[ -1.  -6.   3. 699.]\n",
      "Running reward for the 4 bandits:[  0.  -8.   4. 743.]\n",
      "Running reward for the 4 bandits:[  0.  -8.   4. 787.]\n",
      "Running reward for the 4 bandits:[ -1.  -8.   4. 834.]\n",
      "\n",
      " The agent thinks bandit 4 is the most promising.\n",
      "...and it was right\n"
     ]
    }
   ],
   "source": [
    "#에이전트를 학습시킬 총 에피소드의 수를 구함\n",
    "total_episodes = 1000\n",
    "\n",
    "#밴딧 손잡이에 대한 점수판을 0으로 설정\n",
    "total_reward = np.zeros(num_bandits)\n",
    "\n",
    "e = 0.1 #랜덤 액션의 확률분포 값\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    i = 0\n",
    "    while i < total_episodes:\n",
    "        if np.random.rand(1) < e:\n",
    "            action = np.random.randint(num_bandits)\n",
    "        else:\n",
    "            action = sess.run(chosen_action)\n",
    "            \n",
    "        #Get our reward from picking one of the bandits.     \n",
    "        reward = pull_bandit(bandits[action]) \n",
    "        \n",
    "        #Update the network\n",
    "        _, resp, ww = sess.run([update, responsible_weight, weights],\\\n",
    "                               feed_dict={reward_holder:[reward], action_holder:[action]})\n",
    "        \n",
    "        #보상의 총량 업데이트\n",
    "        total_reward[action] += reward\n",
    "        if i % 50 == 0:\n",
    "            print(\"Running reward for the \" + str(num_bandits) +\" bandits:\" + str(total_reward))\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "print(\"\\n The agent thinks bandit \" + str(np.argmax(ww) + 1) + \" is the most promising.\")\n",
    "if np.argmax(ww) == np.argmax(-np.array(bandit_arms)):\n",
    "    print(\"...and it was right\")\n",
    "else:\n",
    "    print(\"...and it was wrong\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
